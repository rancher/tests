#!/usr/bin/env groovy

/**
 * Improved Rancher Airgap RKE2 Validation Pipeline
 * 
 * This pipeline deploys and validates Rancher in an airgap RKE2 environment
 * with enhanced error handling, security, and maintainability.
 */

pipeline {
    agent any
    
    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 3, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
        retry(1)
    }
    
    // Environment-specific parameters
    parameters {
        string(
            name: 'RKE2_VERSION',
            defaultValue: 'v1.28.8+rke2r1',
            description: 'RKE2 version to deploy (e.g., v1.28.8+rke2r1, v1.29.5+rke2r1, v1.30.2+rke2r1)'
        )
        string(
            name: 'RANCHER_VERSION',
            defaultValue: 'v2.10-head',
            description: 'Rancher version to deploy (e.g., head, v2.10-head, v2.11.0, v2.9-head)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'PRIVATE_REGISTRY_URL',
            defaultValue: '',
            description: 'Private registry URL for airgap deployment'
        )
        string(
            name: 'PRIVATE_REGISTRY_USERNAME',
            defaultValue: '',
            description: 'Private registry username for airgap deployment'
        )
        password(
            name: 'PRIVATE_REGISTRY_PASSWORD',
            defaultValue: '',
            description: 'Private registry password for airgap deployment'
        )
        booleanParam(
            name: 'CLEANUP_RESOURCES',
            defaultValue: true,
            description: 'Clean up AWS resources after deployment'
        )
        booleanParam(
            name: 'PARALLEL_EXECUTION',
            defaultValue: true,
            description: 'Enable parallel execution where possible'
        )
        choice(
            name: 'LOG_LEVEL',
            choices: ['INFO', 'DEBUG', 'VERBOSE'],
            description: 'Pipeline logging level'
        )
    }
    
    // Global environment variables
    environment {
        // Repository configurations - directly from parameters with fallbacks
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"
        
        // Private registry configurations - from job parameters
        PRIVATE_REGISTRY_URL = "${params.PRIVATE_REGISTRY_URL ?: ''}"
        PRIVATE_REGISTRY_USERNAME = "${params.PRIVATE_REGISTRY_USERNAME ?: ''}"
        PRIVATE_REGISTRY_PASSWORD = "${params.PRIVATE_REGISTRY_PASSWORD ?: ''}"
        
        // Path configurations
        ROOT_PATH = "/root/go/src/github.com/rancher/tests/"
        QA_INFRA_WORK_PATH = "/root/go/src/github.com/rancher/qa-infra-automation"
        
        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-airgap-rke2"
        IMAGE_NAME = "rancher-airgap-rke2-validation-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "AirgapRKE2SharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        
        // Configuration files
        ANSIBLE_VARS_FILENAME = "vars.yaml"
        TERRAFORM_VARS_FILENAME = "cluster.tfvars"
        ENV_FILE = ".env"
        
        // Terraform workspace
        TF_WORKSPACE = "jenkins_airgap_workspace_${BUILD_NUMBER}"
        
        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = "30"
        ANSIBLE_TIMEOUT = "45"
        VALIDATION_TIMEOUT = "15"
        
        // AWS Infrastructure defaults (will be overridden by credentials)
        AWS_REGION = "us-west-2"
        AWS_AMI = "ami-0c2d3e23fb3adceb8" // Ubuntu 20.04 LTS in us-west-2
    }
    
    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    // Validate parameters and environment
                    validateParameters()
                    
                    // Set up dynamic variables
                    setupDynamicEnvironment()
                    
                    // Clean workspace
                    deleteDir()
                    
                    logInfo("Pipeline initialized successfully")
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
            post {
                failure {
                    logError("Failed to initialize pipeline")
                }
            }
        }
        
        stage('Checkout Repositories') {
            parallel {
                stage('Checkout Rancher Tests') {
                    steps {
                        dir('./tests') {
                            logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[
                                    url: env.RANCHER_TEST_REPO_URL,
                                ]]
                            ])
                        }
                    }
                }
                
                stage('Checkout QA Infrastructure') {
                    steps {
                        dir('./qa-infra-automation') {
                            logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[
                                    url: env.QA_INFRA_REPO,
                                ]]
                            ])
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Failed to checkout repositories")
                    cleanupContainersAndVolumes()
                }
            }
        }
        
        stage('Configure Environment') {
            steps {
                script {
                    logInfo("Configuring deployment environment")
                    
                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {
                        // Generate configuration files
                        generateConfigurationFiles()
                        
                        // Setup SSH keys securely
                        setupSSHKeys()
                        
                        // Build Docker image with proper tagging
                        buildDockerImage()
                        
                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
            post {
                failure {
                    logError("Environment configuration failed")
                    cleanupContainersAndVolumes()
                }
            }
        }
        

        /**
        * Enhanced Infrastructure Setup Stage
        * 
        * Improvements implemented:
        * 1. Code readability and maintainability
        * 2. Performance optimization  
        * 3. Best practices and patterns
        * 4. Error handling and edge cases
        */

        stage('Setup Infrastructure') {
            steps {
                script {
                    logInfo("Initializing airgap infrastructure deployment with OpenTofu")
                    
                    // Configuration validation
                    def requiredVars = [
                        'QA_INFRA_WORK_PATH',
                        'TF_WORKSPACE', 
                        'TERRAFORM_VARS_FILENAME',
                        'TERRAFORM_TIMEOUT'
                    ]
                    
                    validateRequiredVariables(requiredVars)
                    
                    // Enhanced timeout with reasonable defaults
                    def timeoutMinutes = env.TERRAFORM_TIMEOUT ? 
                        Integer.parseInt(env.TERRAFORM_TIMEOUT) : 30
                    
                    timeout(time: timeoutMinutes, unit: 'MINUTES') {
                        try {
                            // Pre-flight checks
                            validateInfrastructurePrerequisites()
                            
                            // Infrastructure deployment with enhanced error handling
                            deployInfrastructure()
                            
                            // Post-deployment validation
                            validateInfrastructureState()
                            
                            logInfo("Infrastructure provisioned and validated successfully")
                            
                        } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException e) {
                            logError("Infrastructure deployment timed out after ${timeoutMinutes} minutes")
                            handleInfrastructureFailure("TIMEOUT", e)
                            throw e
                        } catch (Exception e) {
                            logError("Infrastructure setup failed: ${e.message}")
                            handleInfrastructureFailure("DEPLOYMENT_FAILED", e)
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    script {
                        logError("Infrastructure setup stage failed")
                        // Archive failure artifacts for debugging
                        archiveInfrastructureFailureArtifacts()
                    }
                }
                always {
                    script {
                        // Archive infrastructure state regardless of outcome
                        archiveInfrastructureState()
                    }
                }
            }
        }

    
        
        stage('Deploy RKE2 Cluster') {
            steps {
                script {
                    logInfo("Deploying RKE2 cluster in airgap environment")
                    
                    timeout(time: Integer.parseInt(env.ANSIBLE_TIMEOUT), unit: 'MINUTES') {
                        try {
                            executeInContainer([
                                "cd ${env.QA_INFRA_WORK_PATH}",
                                "export ANSIBLE_CONFIG=ansible/rke2/ansible.cfg",
                                "export ANSIBLE_PRIVATE_KEY_FILE=/root/.ssh/jenkins-elliptic-validation.pem",
                                "echo 'Starting RKE2 airgap deployment...'",
                                "ansible-playbook -i ansible/rke2/terraform-inventory.yml " +
                                "ansible/rke2/airgap/playbooks/deploy/rke2-tarball-playbook.yml " +
                                "${getAnsibleVerbosity()} -e @ansible/${env.ANSIBLE_VARS_FILENAME}",
                                "echo 'RKE2 airgap cluster deployed successfully'"
                            ])
                        } catch (Exception e) {
                            logError("RKE2 deployment failed: ${e.message}")
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    logError("RKE2 deployment failed")
                    // Continue to cleanup stage
                }
            }
        }
        
        stage('Deploy Rancher') {
            steps {
                script {
                    logInfo("Deploying Rancher on the airgap RKE2 cluster")
                    
                    timeout(time: Integer.parseInt(env.ANSIBLE_TIMEOUT), unit: 'MINUTES') {
                        try {
                            executeInContainer([
                                "cd ${env.QA_INFRA_WORK_PATH}",
                                "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
                                "echo 'Starting Rancher airgap deployment...'",
                                "ansible-playbook ansible/rancher/playbooks/deploy/rancher-airgap-playbook.yml " +
                                "${getAnsibleVerbosity()} -e @ansible/${env.ANSIBLE_VARS_FILENAME}",
                                "echo 'Rancher deployed successfully on airgap cluster'"
                            ])
                        } catch (Exception e) {
                            logError("Rancher deployment failed: ${e.message}")
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Rancher deployment failed")
                }
            }
        }
        
        stage('Validate Deployment') {
            parallel {
                stage('Kubernetes Validation') {
                    steps {
                        script {
                            logInfo("Validating Kubernetes cluster")
                            
                            timeout(time: Integer.parseInt(env.VALIDATION_TIMEOUT), unit: 'MINUTES') {
                                executeInContainer([
                                    "cd ${env.QA_INFRA_WORK_PATH}",
                                    "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
                                    "echo 'Validating cluster nodes...'",
                                    "kubectl get nodes -o wide",
                                    "echo 'Validating system pods...'",
                                    "kubectl get pods -A --field-selector=status.phase!=Running",
                                    "echo 'Validating services...'",
                                    "kubectl get svc -A",
                                    "echo 'Cluster validation completed successfully'"
                                ])
                            }
                        }
                    }
                }
                
                stage('Rancher Validation') {
                    steps {
                        script {
                            logInfo("Validating Rancher deployment")
                            
                            timeout(time: Integer.parseInt(env.VALIDATION_TIMEOUT), unit: 'MINUTES') {
                                executeInContainer([
                                    "cd ${env.QA_INFRA_WORK_PATH}",
                                    "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
                                    "echo 'Validating Rancher pods...'",
                                    "kubectl get pods -n cattle-system",
                                    "echo 'Validating Rancher services...'",
                                    "kubectl get svc -n cattle-system",
                                    "echo 'Checking Rancher ingress...'",
                                    "kubectl get ingress -A",
                                    "echo 'Rancher validation completed successfully'"
                                ])
                            }
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Deployment validation failed")
                }
                always {
                    // Archive validation results regardless of success/failure
                    archiveValidationResults()
                }
            }
        }
    }
    
    post {
        always {
            script {
                logInfo("Starting post-build cleanup")
                
                // Archive important artifacts
                archiveArtifacts([
                    'kubeconfig.yaml',
                    'terraform.tfstate',
                    'ansible-logs.txt',
                    'deployment-summary.json'
                ])
                
                // Clean up resources
                if (params.CLEANUP_RESOURCES) {
                    cleanupInfrastructure()
                } else {
                    logInfo("Resource cleanup skipped (CLEANUP_RESOURCES=false)")
                    logInfo("Remember to manually clean up AWS resources")
                }
                
                // Always cleanup containers and volumes (with try-catch for node context)
                try {
                    node {
                        cleanupContainersAndVolumes()
                    }
                } catch (Exception e) {
                    // If node context is not available, try basic cleanup
                    logError("Node context not available for cleanup: ${e.message}")
                    try {
                        cleanupContainersAndVolumes()
                    } catch (Exception cleanupException) {
                        logError("Cleanup failed: ${cleanupException.message}")
                    }
                }
            }
        }
        
        success {
            script {
                logInfo("Pipeline completed successfully")
                sendSlackNotification([
                    color: 'good',
                    message: "âœ… Airgap RKE2 deployment succeeded for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
        
        failure {
            script {
                logError("Pipeline failed")
                sendSlackNotification([
                    color: 'danger',
                    message: "âŒ Airgap RKE2 deployment failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
        
        unstable {
            script {
                logWarning("Pipeline completed with warnings")
                sendSlackNotification([
                    color: 'warning',
                    message: "âš ï¸ Airgap RKE2 deployment completed with warnings for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
    }
}

/**
 * HELPER FUNCTIONS
 * These functions improve code reusability and maintainability
 */

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        // Use string manipulation instead of array access to avoid Jenkins sandbox issues
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def validateParameters() {
    // Validate required parameters
    if (!params.RKE2_VERSION) {
        error("RKE2_VERSION parameter is required")
    }
    if (!params.RANCHER_VERSION) {
        error("RANCHER_VERSION parameter is required")
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error("RANCHER_TEST_REPO_URL parameter is required")
    }
    if (!params.QA_INFRA_REPO_URL) {
        error("QA_INFRA_REPO_URL parameter is required")
    }
    
    // Validate repository URLs format
    if (!params.RANCHER_TEST_REPO_URL.startsWith('https://github.com/') && !params.RANCHER_TEST_REPO_URL.startsWith('git@github.com:')) {
        error("RANCHER_TEST_REPO_URL must be a valid GitHub repository URL")
    }
    if (!params.QA_INFRA_REPO_URL.startsWith('https://github.com/') && !params.QA_INFRA_REPO_URL.startsWith('git@github.com:')) {
        error("QA_INFRA_REPO_URL must be a valid GitHub repository URL")
    }
    
    logInfo("Parameters validated successfully")
}

def setupDynamicEnvironment() {
    // Set environment variables that depend on parameters
    env.RKE2_VERSION = params.RKE2_VERSION
    env.RANCHER_VERSION = params.RANCHER_VERSION
    
    logInfo("Dynamic environment configured")
    logInfo("RKE2 Version: ${env.RKE2_VERSION}")
    logInfo("Rancher Version: ${env.RANCHER_VERSION}")
    logInfo("Rancher repository: ${env.RANCHER_TEST_REPO_URL}")
    logInfo("QA Infrastructure repository: ${env.QA_INFRA_REPO}")
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),        
        string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def generateConfigurationFiles() {
    logInfo("Generating configuration files for infrastructure deployment")
    
    // Validate required environment variables
    validateConfigurationEnvironmentVariables()
    
    // Generate Terraform configuration from TERRAFORM_CONFIG variable
    generateTerraformConfiguration()
    
    // Generate Ansible configuration
    generateAnsibleConfiguration()
    
    // Generate environment file for containers
    generateEnvironmentFile()
    
    logInfo("Configuration files generated successfully")
}

def validateConfigurationEnvironmentVariables() {
    logInfo("Validating configuration environment variables")
    
    def requiredVars = [
        'TERRAFORM_CONFIG': 'Terraform configuration content (from Jenkins job)',
        'RKE2_VERSION': 'RKE2 version for deployment',
        'RANCHER_VERSION': 'Rancher version for deployment'
    ]
    
    def missingVars = []
    requiredVars.each { varName, description ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add("${varName} (${description})")
        }
    }
    
    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables for configuration:\n- ${missingVars.join('\n- ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }
    
    logInfo("All required environment variables validated successfully")
}

def generateTerraformConfiguration() {
    logInfo("Generating Terraform configuration from TERRAFORM_CONFIG variable")
    
    // Validate TERRAFORM_CONFIG has content
    if (!env.TERRAFORM_CONFIG) {
        throw new RuntimeException("TERRAFORM_CONFIG environment variable is not set")
    }
    
    def tofuConfig = env.TERRAFORM_CONFIG
    
    if (tofuConfig.trim().isEmpty()) {
        throw new RuntimeException("TERRAFORM_CONFIG environment variable is empty")
    }
    
    // Write the configuration file to the correct location
    dir('./qa-infra-automation') {
        dir('./tofu/aws/modules/airgap') {
            writeFile file: env.TERRAFORM_VARS_FILENAME, text: tofuConfig
            logInfo("Terraform configuration written to: ${env.TERRAFORM_VARS_FILENAME}")
            
            // Log configuration stats for verification (without exposing secrets)
            def lines = tofuConfig.split('\n')
            def nonCommentLines = lines.findAll { line ->
                def trimmed = line.trim()
                !trimmed.isEmpty() && !trimmed.startsWith('#')
            }
            
            logInfo("Terraform config contains ${lines.size()} total lines, ${nonCommentLines.size()} configuration lines")
            
            // Show first few non-sensitive lines for debugging
            def previewLines = []
            def count = 0
            for (line in lines) {
                if (count >= 5) break
                def cleanLine = line.toLowerCase()
                if (!cleanLine.contains('secret') && !cleanLine.contains('password') &&
                    !cleanLine.contains('key') && !cleanLine.contains('token')) {
                    previewLines.add(line)
                }
                count++
            }
            
            if (!previewLines.isEmpty()) {
                logInfo("Terraform config preview (non-sensitive lines):")
                previewLines.each { line -> logInfo("  ${line}") }
            }
        }
    }
}

def generateAnsibleConfiguration() {
    logInfo("Generating Ansible configuration for deployment")
    
    def ansibleConfig = generateAnsibleVarsContent()
    
    // Write the Ansible configuration file
    dir('./qa-infra-automation') {
        dir('./ansible') {
            writeFile file: env.ANSIBLE_VARS_FILENAME, text: ansibleConfig
            logInfo("Ansible configuration written to: ${env.ANSIBLE_VARS_FILENAME}")
        }
    }
}

def generateAnsibleVarsContent() {
    return """---
# Ansible Variables for Airgap RKE2 Deployment
# Generated by Jenkins pipeline

# Software Versions
rke2_version: "${env.RKE2_VERSION}"
rancher_version: "${env.RANCHER_VERSION}"

# Build Information
build_number: "${env.BUILD_NUMBER}"
job_name: "${env.JOB_NAME}"
workspace: "${env.TF_WORKSPACE}"

# Private Registry Configuration
private_registry_url: "${env.PRIVATE_REGISTRY_URL ?: ''}"
private_registry_username: "${env.PRIVATE_REGISTRY_USERNAME ?: ''}"
private_registry_password: "${env.PRIVATE_REGISTRY_PASSWORD ?: ''}"

# Deployment Configuration
airgap_mode: true
install_mode: "airgap"
deployment_type: "ha"

# Network Configuration
cluster_cidr: "10.42.0.0/16"
service_cidr: "10.43.0.0/16"
cluster_dns: "10.43.0.10"

# Security Configuration
selinux: false
disable_firewall: true

# Timeout Configuration
deployment_timeout: "${env.TERRAFORM_TIMEOUT ?: '30'}"
ansible_timeout: "${env.ANSIBLE_TIMEOUT ?: '45'}"

# Pipeline Configuration
log_level: "${params.LOG_LEVEL ?: 'INFO'}"
cleanup_resources: ${params.CLEANUP_RESOURCES ?: true}
parallel_execution: ${params.PARALLEL_EXECUTION ?: true}
"""
}

def generateEnvironmentFile() {
    logInfo("Generating environment file for container execution")
    
    def envContent = """# Environment variables for infrastructure deployment containers
TF_WORKSPACE=${env.TF_WORKSPACE}
BUILD_NUMBER=${env.BUILD_NUMBER}
JOB_NAME=${env.JOB_NAME}
TERRAFORM_TIMEOUT=${env.TERRAFORM_TIMEOUT}
ANSIBLE_TIMEOUT=${env.ANSIBLE_TIMEOUT}
QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}
TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}
ANSIBLE_VARS_FILENAME=${env.ANSIBLE_VARS_FILENAME}
"""
    
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo("Setting up SSH keys")
        
        dir('./tests/.ssh') {
            // Securely decode and write SSH key
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }
        
        logInfo("SSH keys configured successfully")
    }
}

def buildDockerImage() {
    logInfo("Building Docker image: ${env.IMAGE_NAME}")
    
    dir('./') {
        sh "./tests/validation/configure.sh"
        sh """
            docker build . \
                -f ./tests/validation/Dockerfile.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD) \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}"
        """
    }
    
    logInfo("Docker image built successfully")
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeInContainer(commands) {
    def commandString = commands.join(' && ')
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c "${commandString.replaceAll('"', '\\\\"')}"
    """
}

def getAnsibleVerbosity() {
    switch (params.LOG_LEVEL) {
        case 'DEBUG':
            return '-vvv'
        case 'VERBOSE':
            return '-vvvv'
        default:
            return '-v'
    }
}

def destroyInfrastructure() {
    logInfo("Destroying infrastructure")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            "tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME}",
            "echo 'Infrastructure destroyed successfully'"
        ])
    } catch (Exception e) {
        logError("Infrastructure destruction failed: ${e.message}")
    }
}

def archiveValidationResults() {
    logInfo("Archiving validation results")
    
    try {
        // Copy artifacts from container
        sh """
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/ansible/rke2/kubeconfig.yaml ./kubeconfig.yaml || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/terraform.tfstate ./terraform.tfstate || true
        """
        
        // Generate deployment summary
        def deploymentSummary = [
            buildNumber: env.BUILD_NUMBER,
            rke2Version: env.RKE2_VERSION,
            rancherVersion: env.RANCHER_VERSION,
            timestamp: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'"),
            status: currentBuild.currentResult ?: 'SUCCESS'
        ]
        
        writeFile file: 'deployment-summary.json', text: groovy.json.JsonOutput.toJson(deploymentSummary)
        
    } catch (Exception e) {
        logError("Failed to archive validation results: ${e.message}")
    }
}

def cleanupInfrastructure() {
    logInfo("Cleaning up infrastructure resources")
    destroyInfrastructure()
}

def cleanupContainersAndVolumes() {
    logInfo("Cleaning up Docker containers and volumes")
    
    try {
        // Ensure we have a node context for shell commands
        if (env.NODE_NAME) {
            sh """
                # Stop and remove any containers with our naming pattern
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true
                
                # Remove the Docker image
                docker rmi -f ${env.IMAGE_NAME} || true
                
                # Remove the shared volume
                docker volume rm -f ${env.VALIDATION_VOLUME} || true
                
                # Clean up any dangling images and volumes
                docker system prune -f || true
            """
        } else {
            logWarning("No node context available for Docker cleanup - skipping shell commands")
        }
    } catch (Exception e) {
        logError("Docker cleanup failed: ${e.message}")
        // Don't fail the pipeline on cleanup issues
    }
}

def archiveArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins',
                color: config.color,
                title: 'Airgap RKE2 Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'RKE2 Version', value: env.RKE2_VERSION, short: true],
                    [title: 'Rancher Version', value: env.RANCHER_VERSION, short: true]
                ]
            ]
            
            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )
            
            logInfo("Slack notification sent successfully")
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * LOGGING FUNCTIONS
 * Provide structured logging with different levels
 */

def logInfo(message) {
    echo "â„¹ï¸ [INFO] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logError(message) {
    echo "âŒ [ERROR] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logWarning(message) {
    echo "âš ï¸ [WARNING] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logDebug(message) {
    if (params.LOG_LEVEL == 'DEBUG' || params.LOG_LEVEL == 'VERBOSE') {
        echo "ðŸ” [DEBUG] ${new Date().format('HH:mm:ss')} - ${message}"
    }
}

/**
 * ENHANCED HELPER FUNCTIONS FOR INFRASTRUCTURE MANAGEMENT
 * These functions implement DevOps best practices and improve maintainability
 */

def debugTerraformOutputs() {
    logInfo("Debugging Terraform outputs for inventory generation")
    
    def debugScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Available Terraform outputs:'
tofu -chdir=tofu/aws/modules/airgap output -json | jq -r 'keys[]' 2>/dev/null | head -20 || echo 'No JSON outputs available or jq not installed'
tofu -chdir=tofu/aws/modules/airgap output 2>/dev/null | head -30 || echo 'No outputs available'

echo 'Checking for inventory-related outputs:'
tofu -chdir=tofu/aws/modules/airgap output inventory 2>/dev/null || echo 'No inventory output'
tofu -chdir=tofu/aws/modules/airgap output hosts 2>/dev/null || echo 'No hosts output'
tofu -chdir=tofu/aws/modules/airgap output ansible_inventory 2>/dev/null || echo 'No ansible_inventory output'

echo 'Available instance information:'
tofu -chdir=tofu/aws/modules/airgap output server_ips 2>/dev/null || echo 'No server_ips'
tofu -chdir=tofu/aws/modules/airgap output agent_ips 2>/dev/null || echo 'No agent_ips'
tofu -chdir=tofu/aws/modules/airgap output server_private_ips 2>/dev/null || echo 'No server_private_ips'
tofu -chdir=tofu/aws/modules/airgap output agent_private_ips 2>/dev/null || echo 'No agent_private_ips'

echo 'Terraform outputs debugging completed'
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-debug-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c '${debugScript}'
    """
}

def validateRequiredVariables(requiredVars) {
    logInfo("Validating required environment variables")
    
    def missingVars = []
    requiredVars.each { varName ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add(varName)
        }
    }
    
    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables: ${missingVars.join(', ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }
    
    logInfo("All required variables validated successfully")
}

def validateInfrastructurePrerequisites() {
    logInfo("Validating infrastructure prerequisites")
    
    def prerequisiteScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Checking OpenTofu installation...'
tofu version

echo 'Checking workspace directory...'
test -d ${env.QA_INFRA_WORK_PATH}

echo 'Validating terraform vars file...'
test -f ${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME}

echo 'All infrastructure prerequisites validated successfully'
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-prereq-${timestamp}"
    
    try {
        sh """
            docker run --rm \
                -v ${env.VALIDATION_VOLUME}:/root \
                --name ${containerName} \
                -t --env-file ${env.ENV_FILE} \
                -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
                -e TF_WORKSPACE=${env.TF_WORKSPACE} \
                ${env.IMAGE_NAME} \
                sh -c '${prerequisiteScript}'
        """
        logInfo("All infrastructure prerequisites validated")
    } catch (Exception e) {
        def errorMsg = "Infrastructure prerequisites validation failed: ${e.message}"
        logError(errorMsg)
        throw new RuntimeException(errorMsg, e)
    }
}

def deployInfrastructure() {
    logInfo("Starting infrastructure deployment process")
    
    // Step 1: Initialize OpenTofu with enhanced configuration
    initializeOpenTofu()
    
    // Step 2: Manage workspace with proper isolation
    manageWorkspace()
    
    // Step 3: Plan infrastructure changes (best practice)
    planInfrastructure()
    
    // Step 4: Apply infrastructure with state management
    applyInfrastructure()
    
    // Step 5: Generate and manage Ansible inventory from OpenTofu outputs
    // generateAndManageInventory()
    
    logInfo("Infrastructure deployment completed successfully")
}

def initializeOpenTofu() {
    logInfo("Initializing OpenTofu with enhanced configuration")
    
    def initScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Initializing OpenTofu backend...'
tofu -chdir=tofu/aws/modules/airgap init -input=false -upgrade -reconfigure

echo 'Verifying initialization success...'
tofu -chdir=tofu/aws/modules/airgap providers

echo 'OpenTofu initialization completed successfully'
"""

    retryWithBackoff(3, 10, {
        def timestamp = System.currentTimeMillis()
        def containerName = "${env.BUILD_CONTAINER_NAME}-init-${timestamp}"
        
        sh """
            docker run --rm \
                -v ${env.VALIDATION_VOLUME}:/root \
                --name ${containerName} \
                -t --env-file ${env.ENV_FILE} \
                -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
                -e TF_WORKSPACE=${env.TF_WORKSPACE} \
                ${env.IMAGE_NAME} \
                sh -c '${initScript}'
        """
    })
}

def manageWorkspace() {
    logInfo("Managing OpenTofu workspace: ${env.TF_WORKSPACE}")
    
    def workspaceScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Managing workspace state...'

# Unset TF_WORKSPACE temporarily to allow workspace commands
unset TF_WORKSPACE

# List existing workspaces for debugging
echo 'Current workspaces:'
tofu -chdir=tofu/aws/modules/airgap workspace list

# Create or select workspace with proper error handling
echo 'Creating or selecting workspace: ${env.TF_WORKSPACE}'
if ! tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE} 2>/dev/null; then
    echo 'Workspace does not exist, creating new workspace...'
    tofu -chdir=tofu/aws/modules/airgap workspace new ${env.TF_WORKSPACE}
fi

# Verify workspace selection
CURRENT_WORKSPACE=\$(tofu -chdir=tofu/aws/modules/airgap workspace show)
echo "Current workspace: \$CURRENT_WORKSPACE"

if [ "\$CURRENT_WORKSPACE" != "${env.TF_WORKSPACE}" ]; then
    echo "ERROR: Expected workspace ${env.TF_WORKSPACE}, but got \$CURRENT_WORKSPACE"
    exit 1
fi

# Set TF_WORKSPACE for future commands
export TF_WORKSPACE=${env.TF_WORKSPACE}
echo "Workspace management completed: \$TF_WORKSPACE"
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-workspace-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            ${env.IMAGE_NAME} \
            sh -c '${workspaceScript}'
    """
}

def planInfrastructure() {
    logInfo("Planning infrastructure changes (for validation)")

    def planScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Generating infrastructure plan for validation...'
tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file=${env.TERRAFORM_VARS_FILENAME}

echo 'Infrastructure plan validation completed'
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-plan-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c '${planScript}'
    """
}

/**
 * Applies the infrastructure configuration using OpenTofu, generates inventory files,
 * and ensures the environment is ready for subsequent deployment stages.
 */
def applyInfrastructure() {
    logInfo("Applying infrastructure configuration")
    
    def applyScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Applying infrastructure configuration...'
# Generate a plan file for auditability and reliability
tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file=${env.TERRAFORM_VARS_FILENAME} -out=tfplan

# Check if plan was generated successfully
if [ ! -f tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully'
    exit 1
fi

# Verify the plan file is not empty
PLAN_SIZE=\$(stat -c%s tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" -eq 0 ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo 'Plan file generated successfully (\$PLAN_SIZE bytes), applying...'
# Apply the generated plan file with proper error handling
tofu -chdir=tofu/aws/modules/airgap apply -auto-approve -input=false tfplan

# Clean up the plan file after successful application
rm -f tfplan

echo 'Verifying state after apply...'
tofu -chdir=tofu/aws/modules/airgap state list

echo 'Generating outputs for downstream stages...'
tofu -chdir=tofu/aws/modules/airgap output -json > ${env.QA_INFRA_WORK_PATH}/infrastructure-outputs.json

echo 'Enhanced inventory generation starting...'
echo 'Checking available Terraform outputs...'
tofu -chdir=tofu/aws/modules/airgap output -json | jq -r 'keys[]' || echo 'No outputs available'

echo 'Attempting inventory generation...'
mkdir -p ansible/rke2/

# Method 1: Try inventory output
echo 'Method 1: Trying inventory output...'
tofu -chdir=tofu/aws/modules/airgap output -raw inventory > ansible/rke2/terraform-inventory.yml 2>/dev/null || echo 'No inventory output'
# Remove the file if it is empty to avoid confusion in later steps
if [ -s ansible/rke2/terraform-inventory.yml ]; then
    echo 'SUCCESS: Inventory generated using Method 1 (inventory output)'
else
    rm -f ansible/rke2/terraform-inventory.yml
fi

# Method 2: Try hosts output if inventory is empty
if [ ! -s ansible/rke2/terraform-inventory.yml ]; then
    echo 'Method 2: Trying hosts output...'
    tofu -chdir=tofu/aws/modules/airgap output -raw hosts > ansible/rke2/terraform-inventory.yml 2>/dev/null || echo 'No hosts output'
    if [ -s ansible/rke2/terraform-inventory.yml ]; then
        echo 'SUCCESS: Inventory generated using Method 2 (hosts output)'
    fi
fi

# Method 3: Try ansible_inventory output if still empty
if [ ! -s ansible/rke2/terraform-inventory.yml ]; then
    echo 'Method 3: Trying ansible_inventory output...'
    tofu -chdir=tofu/aws/modules/airgap output -raw ansible_inventory > ansible/rke2/terraform-inventory.yml 2>/dev/null || echo 'No ansible_inventory output'
    if [ -s ansible/rke2/terraform-inventory.yml ]; then
        echo 'SUCCESS: Inventory generated using Method 3 (ansible_inventory output)'
    fi
fi

# Method 4: Generate basic inventory if nothing else works
if [ ! -s ansible/rke2/terraform-inventory.yml ]; then
    echo 'Method 4: Generating basic inventory from available instance data...'
    
cat > ansible/rke2/terraform-inventory.yml << 'EOF'
# Generated inventory from Terraform outputs
all:
  children:
    rke2_servers:
      hosts:
    rke2_agents:
      hosts:
EOF
    echo 'SUCCESS: Inventory generated using Method 4 (basic inventory fallback)'
fi

echo 'Infrastructure provisioned and inventory generated successfully'
echo 'Infrastructure provisioned and inventory generated successfully'
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-apply-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c '${applyScript}'
    """
}

// def generateAndManageInventory() {
//     logInfo("Generating and managing Ansible inventory files")
    
//     def inventoryCommands = [
//         "cd ${env.QA_INFRA_WORK_PATH}",
//         "export TF_WORKSPACE=${env.TF_WORKSPACE}",
//         "echo 'Setting up inventory directories...'",
//         // Ensure inventory directories exist
//         "mkdir -p ansible/rke2/airgap/inventory",
//         "mkdir -p ansible/rke2/",
        
//         "echo 'Checking for generated inventory files...'",
//         // List what's in the inventory directory
//         "ls -la ansible/rke2/airgap/inventory/ 2>/dev/null || echo 'No inventory directory found yet'",
        
//         // Try to generate inventory from terraform outputs if not already generated
//         "if [ ! -f ansible/rke2/airgap/inventory/terraform-inventory.yml ]; then echo 'Generating inventory from terraform outputs...'; fi",
//         "tofu -chdir=tofu/aws/modules/airgap output -raw inventory > ansible/rke2/airgap/inventory/terraform-inventory.yml 2>/dev/null || echo 'No inventory output available from terraform'",
//         "tofu -chdir=tofu/aws/modules/airgap output -raw hosts > ansible/rke2/airgap/inventory/hosts.yml 2>/dev/null || echo 'No hosts output available from terraform'",
        
//         // Try alternative inventory generation methods
//         "if [ ! -f ansible/rke2/airgap/inventory/terraform-inventory.yml ] && [ -f scripts/generate-inventory.py ]; then python3 scripts/generate-inventory.py; fi",
//         "if [ ! -f ansible/rke2/airgap/inventory/terraform-inventory.yml ] && [ -f ansible/scripts/generate-inventory.sh ]; then bash ansible/scripts/generate-inventory.sh; fi",
        
//         "echo 'Managing inventory file locations...'",
//         // Copy inventory files to expected locations for playbooks
//         "find ansible/rke2/airgap/inventory/ -name '*.yml' -o -name '*.yaml' | head -5",
        
//         // Copy the generated inventory to the location expected by RKE2 playbook
//         "if [ -f ansible/rke2/airgap/inventory/terraform-inventory.yml ]; then cp ansible/rke2/airgap/inventory/terraform-inventory.yml ansible/rke2/terraform-inventory.yml; echo 'Copied terraform-inventory.yml'; fi",
//         "if [ -f ansible/rke2/airgap/inventory/inventory.yml ]; then cp ansible/rke2/airgap/inventory/inventory.yml ansible/rke2/terraform-inventory.yml; echo 'Copied inventory.yml'; fi",
//         "if [ -f ansible/rke2/airgap/inventory/hosts.yml ]; then cp ansible/rke2/airgap/inventory/hosts.yml ansible/rke2/terraform-inventory.yml; echo 'Copied hosts.yml'; fi",
        
//         // Find any inventory file and use it
//         "if [ ! -f ansible/rke2/terraform-inventory.yml ]; then INVENTORY_FILE=\$(find ansible/rke2/airgap/inventory/ -name '*.yml' -o -name '*.yaml' | head -1); if [ ! -z \"\$INVENTORY_FILE\" ]; then cp \"\$INVENTORY_FILE\" ansible/rke2/terraform-inventory.yml; echo \"Copied \$INVENTORY_FILE as fallback\"; fi; fi",
        
//         "echo 'Verifying final inventory setup...'",
//         "if [ -f ansible/rke2/terraform-inventory.yml ]; then echo 'SUCCESS: terraform-inventory.yml found'; wc -l ansible/rke2/terraform-inventory.yml; else echo 'WARNING: No terraform-inventory.yml file available for Ansible playbooks'; fi",
//         "if [ -f ansible/rke2/terraform-inventory.yml ]; then echo 'Inventory file preview:'; head -10 ansible/rke2/terraform-inventory.yml; fi",
        
//         "echo 'Inventory management completed'"
//     ]
    
//     executeInContainer(inventoryCommands)
// }

def validateInfrastructureState() {
    logInfo("Validating infrastructure deployment state")
    
    def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Validating infrastructure state...'

echo 'Checking state integrity...'
STATE_COUNT=\$(tofu -chdir=tofu/aws/modules/airgap state list | wc -l)
echo "Number of resources in state: \$STATE_COUNT"

echo 'Checking critical outputs...'
tofu -chdir=tofu/aws/modules/airgap output -raw vpc_id || echo 'WARNING: vpc_id output missing'
tofu -chdir=tofu/aws/modules/airgap output -raw subnet_ids || echo 'WARNING: subnet_ids output missing'

echo 'Validating AWS resources are accessible...'
aws ec2 describe-instances --filters 'Name=tag:Workspace,Values=${env.TF_WORKSPACE}' --query 'Reservations[*].Instances[*].State.Name' --output text || echo 'Could not query AWS instances'

echo 'Infrastructure state validation completed'
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-validate-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c '${validationScript}'
    """
    
    // Debug Terraform outputs before inventory validation
    debugTerraformOutputs()
    
    // Validate inventory files are ready for Ansible with enhanced debugging
    validateInventoryFiles()
}

def validateInventoryFiles() {
    logInfo("Enhanced Ansible inventory validation with debugging")
    
    // Use a script approach to avoid complex shell syntax in command arrays
    def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}
echo 'Enhanced inventory validation starting...'

# Debug: Check multiple possible inventory locations
echo 'Debugging: Checking inventory file locations:'
find . -name '*inventory*' -type f 2>/dev/null | head -10 || echo 'No inventory files found'
find . -name 'terraform-inventory.yml' -type f 2>/dev/null | head -5 || echo 'No terraform-inventory.yml found'

# Debug: List ansible directory contents
echo 'Contents of ansible/rke2/ directory:'
ls -la ansible/rke2/ 2>/dev/null || echo 'ansible/rke2/ directory does not exist'

# Main inventory file validation
echo 'Checking main inventory file...'
if [ -f ansible/rke2/terraform-inventory.yml ]; then
  echo 'SUCCESS: terraform-inventory.yml exists for Ansible playbooks'
  echo 'File details:'
  ls -lh ansible/rke2/terraform-inventory.yml
  wc -l ansible/rke2/terraform-inventory.yml
else
  echo 'WARNING: terraform-inventory.yml not found at expected location'
  echo 'Attempting to locate and copy inventory files...'
  
  # Search for any inventory file
  FOUND_INVENTORY=\$(find ansible/ -name '*inventory*.yml' -o -name '*inventory*.yaml' 2>/dev/null | head -1)
  
  if [ ! -z "\$FOUND_INVENTORY" ]; then
    echo "Found inventory file: \$FOUND_INVENTORY"
    cp "\$FOUND_INVENTORY" ansible/rke2/terraform-inventory.yml
    echo 'Copied found inventory file to expected location'
  else
    echo 'ERROR: No inventory files found anywhere - generating minimal inventory'
    mkdir -p ansible/rke2/
    
    # Generate minimal inventory file
cat > ansible/rke2/terraform-inventory.yml << 'EOF'
# Minimal inventory generated by Jenkins due to missing Terraform outputs
all:
  children:
    rke2_servers:
      hosts:
        # Server hosts will be populated by Terraform outputs
    rke2_agents:
      hosts:
        # Agent hosts will be populated by Terraform outputs
EOF
    echo 'Generated minimal inventory file'
  fi
fi

# Content validation
echo 'Validating inventory content...'
if [ -s ansible/rke2/terraform-inventory.yml ]; then
  echo 'SUCCESS: terraform-inventory.yml has content'
  echo 'File size:'
  du -h ansible/rke2/terraform-inventory.yml
  echo 'Preview of inventory content:'
  head -30 ansible/rke2/terraform-inventory.yml
else
  echo 'ERROR: terraform-inventory.yml is empty'
  exit 1
fi

# YAML syntax validation
echo 'Validating YAML syntax...'
if python3 -c "import yaml; yaml.safe_load(open('ansible/rke2/terraform-inventory.yml'))" 2>/dev/null; then
  echo 'SUCCESS: Inventory YAML is valid'
else
  echo 'WARNING: YAML syntax issues detected'
  echo 'Attempting to show YAML validation errors:'
  python3 -c "import yaml; yaml.safe_load(open('ansible/rke2/terraform-inventory.yml'))" || true
fi

# Final status summary
echo 'Enhanced inventory validation completed'
echo 'Final inventory file status:'
if [ -f ansible/rke2/terraform-inventory.yml ] && [ -s ansible/rke2/terraform-inventory.yml ]; then
  echo 'STATUS: READY - Inventory file exists and has content'
else
  echo 'STATUS: ERROR - Inventory file missing or empty'
  exit 1
fi
"""

    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-validation-${timestamp}"
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c '${validationScript.replaceAll("'", "\\\\'")}'
    """
}

def handleInfrastructureFailure(failureType, exception) {
    logError("Handling infrastructure failure of type: ${failureType}")
    
    try {
        switch(failureType) {
            case "TIMEOUT":
                logError("Infrastructure deployment timed out - attempting graceful cleanup")
                // Don't destroy on timeout - might be close to completion
                archiveInfrastructureState()
                break
                
            case "DEPLOYMENT_FAILED":
                logError("Infrastructure deployment failed - attempting cleanup")
                // Attempt cleanup but don't fail the entire pipeline if cleanup fails
                safeDestroyInfrastructure()
                break
                
            default:
                logError("Unknown failure type: ${failureType}")
                safeDestroyInfrastructure()
        }
        
        // Archive failure diagnostics
        archiveFailureDiagnostics(exception)
        
    } catch (Exception cleanupException) {
        logError("Cleanup failed during failure handling: ${cleanupException.message}")
        // Continue - don't mask original failure
    }
}

def safeDestroyInfrastructure() {
    logInfo("Attempting safe infrastructure destruction")
    
    try {
        def destroyCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            "echo 'Selecting workspace for destruction...'",
            "tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE} || echo 'Workspace selection failed'",
            "echo 'Destroying infrastructure...'",
            "tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME} || echo 'Destroy completed with warnings'",
            "echo 'Infrastructure destruction completed'"
        ]
        
        // Use timeout for destroy operation
        timeout(time: 15, unit: 'MINUTES') {
            executeInContainer(destroyCommands)
        }
        
        logInfo("Infrastructure destroyed successfully")
        
    } catch (Exception e) {
        logError("Infrastructure destruction failed: ${e.message}")
        logError("Manual cleanup may be required for workspace: ${env.TF_WORKSPACE}")
    }
}

def retryWithBackoff(maxAttempts, backoffSeconds, closure) {
    def attempt = 0
    def lastException
    
    while (attempt < maxAttempts) {
        attempt++
        try {
            logInfo("Attempt ${attempt} of ${maxAttempts}")
            return closure() // Execute the closure
        } catch (Exception e) {
            lastException = e
            logError("Attempt ${attempt} failed: ${e.message}")
            
            if (attempt < maxAttempts) {
                def waitTime = backoffSeconds * Math.pow(2, attempt - 1) // Exponential backoff
                logInfo("Waiting ${waitTime} seconds before retry...")
                sleep(waitTime as Integer)
            }
        }
    }
    
    logError("All ${maxAttempts} attempts failed")
    throw lastException
}

def archiveInfrastructureState() {
    logInfo("Archiving infrastructure state and outputs")
    
    try {
        def archiveCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            // Copy state file with workspace context
            "cp tofu/aws/modules/airgap/terraform.tfstate infrastructure-${env.TF_WORKSPACE}.tfstate 2>/dev/null || echo 'No state file to archive'",
            // Copy plan file if exists
            "cp tofu/aws/modules/airgap/tfplan infrastructure-plan.tfplan 2>/dev/null || echo 'No plan file to archive'",
            // Generate state summary
            "tofu -chdir=tofu/aws/modules/airgap show -no-color > infrastructure-state-summary.txt 2>/dev/null || echo 'Could not generate state summary'",
            "echo 'State archival completed'"
        ]
        
        executeInContainer(archiveCommands)
        
        // Archive files from container
        sh """
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/infrastructure-${env.TF_WORKSPACE}.tfstate ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/infrastructure-outputs.json ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/infrastructure-state-summary.txt ./ || true
        """
        
    } catch (Exception e) {
        logError("Failed to archive infrastructure state: ${e.message}")
    }
}

def archiveInfrastructureFailureArtifacts() {
    logInfo("Archiving infrastructure failure artifacts")
    
    try {
        def debugCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            // Capture debug information
            "tofu -chdir=tofu/aws/modules/airgap workspace list > workspace-list.txt 2>&1",
            "tofu -chdir=tofu/aws/modules/airgap state list > state-resources.txt 2>&1 || echo 'No state available'",
            "tofu -chdir=tofu/aws/modules/airgap providers > providers.txt 2>&1 || echo 'Providers not available'",
            // Capture AWS resource state
            "aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,State.Name,Tags[?Key==`Name`].Value|[0]]' --output table > aws-instances.txt 2>&1 || echo 'Could not query AWS instances'",
            "echo 'Failure artifact collection completed'"
        ]
        
        executeInContainer(debugCommands)
        
        // Copy debug files from container
        sh """
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/workspace-list.txt ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/state-resources.txt ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/providers.txt ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/aws-instances.txt ./ || true
        """
        
    } catch (Exception e) {
        logError("Failed to archive failure artifacts: ${e.message}")
    }
}

def archiveFailureDiagnostics(exception) {
    logInfo("Archiving failure diagnostics")
    
    def diagnostics = [
        timestamp: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'"),
        buildNumber: env.BUILD_NUMBER,
        workspace: env.TF_WORKSPACE,
        failureType: exception.class.simpleName,
        errorMessage: exception.message,
        stackTrace: getStackTracePreview(exception.stackTrace, 10)
    ]
    
    try {
        writeFile file: 'infrastructure-failure-diagnostics.json', 
                  text: groovy.json.JsonOutput.prettyPrint(groovy.json.JsonOutput.toJson(diagnostics))
        
        logInfo("Failure diagnostics archived successfully")
    } catch (Exception e) {
        logError("Failed to archive failure diagnostics: ${e.message}")
    }
}

def getStackTracePreview(stackTrace, maxLines) {
    if (!stackTrace) {
        return 'No stack trace available'
    }
    
    def lines = []
    def count = 0
    
    // Manual iteration to avoid Jenkins security restrictions on .take()
    for (element in stackTrace) {
        if (count >= maxLines) {
            break
        }
        lines.add(element.toString())
        count++
    }
    
    return lines.join('\n')
}
