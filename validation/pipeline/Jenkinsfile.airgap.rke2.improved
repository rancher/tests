#!/usr/bin/env groovy

import groovy.json.JsonOutput

/**
 * Improved Rancher Airgap RKE2 Validation Pipeline
 * 
 * This pipeline deploys and validates Rancher in an airgap RKE2 environment
 * with enhanced error handling, security, and maintainability.
 */

pipeline {
    agent any
    
    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 3, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
        retry(1)
    }
    
    // Environment-specific parameters
    parameters {
        string(
            name: 'RKE2_VERSION',
            defaultValue: 'v1.28.8+rke2r1',
            description: 'RKE2 version to deploy (e.g., v1.28.8+rke2r1, v1.29.5+rke2r1, v1.30.2+rke2r1)'
        )
        string(
            name: 'RANCHER_VERSION',
            defaultValue: 'v2.10-head',
            description: 'Rancher version to deploy (e.g., head, v2.10-head, v2.11.0, v2.9-head)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'PRIVATE_REGISTRY_URL',
            defaultValue: '',
            description: 'Private registry URL for airgap deployment'
        )
        string(
            name: 'PRIVATE_REGISTRY_USERNAME',
            defaultValue: '',
            description: 'Private registry username for airgap deployment'
        )
        password(
            name: 'PRIVATE_REGISTRY_PASSWORD',
            defaultValue: '',
            description: 'Private registry password for airgap deployment'
        )
        booleanParam(
            name: 'CLEANUP_RESOURCES',
            defaultValue: true,
            description: 'Clean up AWS resources after deployment'
        )
        booleanParam(
            name: 'PARALLEL_EXECUTION',
            defaultValue: true,
            description: 'Enable parallel execution where possible'
        )
        choice(
            name: 'LOG_LEVEL',
            choices: ['INFO', 'DEBUG', 'VERBOSE'],
            description: 'Pipeline logging level'
        )
    }
    
    // Global environment variables
    environment {
        // Repository configurations - directly from parameters with fallbacks
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"
        
        // Private registry configurations - from job parameters
        PRIVATE_REGISTRY_URL = "${params.PRIVATE_REGISTRY_URL ?: ''}"
        PRIVATE_REGISTRY_USERNAME = "${params.PRIVATE_REGISTRY_USERNAME ?: ''}"
        PRIVATE_REGISTRY_PASSWORD = "${params.PRIVATE_REGISTRY_PASSWORD ?: ''}"
        
        // Path configurations
        ROOT_PATH = "/root/go/src/github.com/rancher/tests/"
        // Computed values
        JOB_SHORT_NAME = "${env.JOB_NAME ? getShortJobName() : ''}"
        BUILD_CONTAINER_NAME = "${env.JOB_SHORT_NAME ?: ''}${env.BUILD_NUMBER ?: ''}-airgap-rke2"
        IMAGE_NAME = "rancher-airgap-rke2-validation-${env.JOB_SHORT_NAME ?: ''}${env.BUILD_NUMBER ?: ''}"
        VALIDATION_VOLUME = "AirgapRKE2SharedVolume-${env.JOB_SHORT_NAME ?: ''}${env.BUILD_NUMBER ?: ''}"
        
        // Configuration files
        ANSIBLE_VARS_FILENAME = "vars.yaml"
        TERRAFORM_VARS_FILENAME = "cluster.tfvars"
        ENV_FILE = ".env"
        
        // Terraform workspace
        TF_WORKSPACE = "jenkins_airgap_workspace_${env.BUILD_NUMBER ?: ''}"
        
        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = "30"
        ANSIBLE_TIMEOUT = "45"
        VALIDATION_TIMEOUT = "15"
    }
        VALIDATION_TIMEOUT = "15"
    }
    
    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    // Validate parameters and environment
                    validateParameters()
                    
                    // Set up dynamic variables
                    setupDynamicEnvironment()
                    
                    // Clean workspace
                    deleteDir()
                    
                    logInfo("Pipeline initialized successfully")
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
            post {
                failure {
                    logError("Failed to initialize pipeline")
                }
            }
        }
        
        stage('Checkout Repositories') {
            parallel {
                stage('Checkout Rancher Tests') {
                    steps {
                        dir('./tests') {
                            logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[
                                    url: env.RANCHER_TEST_REPO_URL,
                                ]]
                            ])
                        }
                    }
                }
                
                stage('Checkout QA Infrastructure') {
                    steps {
                        dir('./qa-infra-automation') {
                            logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[
                                    url: env.QA_INFRA_REPO,
                                ]]
                            ])
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Failed to checkout repositories")
                    cleanupContainersAndVolumes()
                }
            }
        }
        
        stage('Configure Environment') {
            steps {
                script {
                    logInfo("Configuring deployment environment")
                    
                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {
                        // Generate configuration files
                        generateConfigurationFiles()
                        
                        // Setup SSH keys securely
                        setupSSHKeys()
                        
                        // Build Docker image with proper tagging
                        buildDockerImage()
                        
                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
            post {
                failure {
                    logError("Environment configuration failed")
                    cleanupContainersAndVolumes()
                }
            }
        }
        
        stage('Infrastructure Provisioning') {
            steps {
                script {
                    logInfo("Starting infrastructure provisioning with enhanced validation and monitoring")
                    
                    // Pre-flight validation checks
                    validateInfrastructurePrerequisites()
                    
                    timeout(time: Integer.parseInt(env.TERRAFORM_TIMEOUT), unit: 'MINUTES') {
                        try {
                            // Initialize with state locking and backend validation
                            executeInfrastructureSetup()
                            
                            // Validate infrastructure state
                            validateInfrastructureState()
                            
                            // Cache infrastructure outputs for later stages
                            cacheInfrastructureOutputs()
                            
                        } catch (Exception e) {
                            logError("Infrastructure provisioning failed: ${e.message}")
                            handleInfrastructureFailure(e)
                            throw e
                        }
                    }
                }
            }
            post {
                success {
                    logInfo("Infrastructure provisioning completed successfully")
                    publishInfrastructureMetrics()
                }
                failure {
                    logError("Infrastructure provisioning failed - initiating rollback")
                    script {
                        rollbackInfrastructure()
                    }
                }
            }
        }
        
        stage('Deployment Pipeline') {
            when {
                expression { params.PARALLEL_EXECUTION == true }
            }
            stages {
                stage('RKE2 Deployment') {
                    steps {
                        script {
                            logInfo("Deploying RKE2 cluster with enhanced monitoring for environment: ${env.JOB_NAME}, cluster: ${env.BUILD_CONTAINER_NAME}")

                            timeout(time: Integer.parseInt(env.ANSIBLE_TIMEOUT), unit: 'MINUTES') {
                                try {
                                    // Pre-deployment validation
                                    validateClusterPrerequisites()

                                    // Deploy with progress monitoring
                                    // Enhanced monitoring: runs Ansible playbook with monitoring enabled, logs progress, and collects deployment metrics for troubleshooting.
                                    deployRKE2WithMonitoring()
                                    // Post-deployment validation: checks node readiness, system pods, and waits for all kube-system pods to be ready (see validateClusterHealth())
                                    validateClusterHealth()
                                    validateClusterHealth()

                                } catch (Exception e) {
                                    logError("[RKE2 Deployment] RKE2 deployment failed: ${e.message}")
                                    handleClusterDeploymentFailure(e)
                                    throw e
                                }
                            }
                        }
                    }
                    post {
                        success {
                            // Artifacts archived: kubeconfig.yaml, cluster-info.yaml
                            logInfo("RKE2 cluster deployed successfully")
                            logInfo("Archiving cluster artifacts: kubeconfig.yaml, cluster-info.yaml")
                        }
                        failure {
                            script {
                                logError("RKE2 deployment failed - collecting diagnostic information (diagnostics will be stored in ./cluster-diagnostics/)")
                                // Cluster diagnostics will be archived in the ./cluster-diagnostics/ directory for further analysis.
                                collectClusterDiagnostics()
                            }
                        }
                    }
                }
                stage('Security & Compliance Validation') {
                    when {
                        expression { params.PARALLEL_EXECUTION == true }
                    }
                    steps {
                        script {
                            logInfo("Running security and compliance validations")

                            timeout(time: 10, unit: 'MINUTES') {
                                parallel(
                                    "Network Security": {
                                        validateNetworkSecurity()
                                    },
                                    "Resource Compliance": {
                                        validateResourceCompliance()
                                    },
                                    "Access Controls": {
                                        validateAccessControls()
                                    }
                                )
                            }
                        }
                    }
                }
            }
        }
        
        stage('Rancher Deployment & Integration') {
            steps {
                script {
                    logInfo("Deploying Rancher with integrated health monitoring")
                    
                    timeout(time: Integer.parseInt(env.ANSIBLE_TIMEOUT), unit: 'MINUTES') {
                        try {
                            // Wait for cluster readiness
                            waitForClusterReadiness()
                            
                            // Deploy Rancher with real-time monitoring
                            deployRancherWithMonitoring()
                            
                            // Validate Rancher integration
                            validateRancherIntegration()
                            
                            // Run smoke tests
                            runRancherSmokeTests()
                            
                        } catch (Exception e) {
                            logError("Rancher deployment failed: ${e.message}")
                            handleRancherDeploymentFailure(e)
                            throw e
                        }
                    }
                }
            }
            post {
                success {
                    logInfo("Rancher deployment completed successfully")
                    publishDeploymentMetrics()
                }
                failure {
                    script {
                        logError("Rancher deployment failed - collecting diagnostic data")
                        collectRancherDiagnostics()
                    }
                }
            }
        }
        
        stage('Validate Deployment') {
            parallel {
                stage('Kubernetes Validation') {
                    steps {
                        script {
                            logInfo("Validating Kubernetes cluster")
                            
                            timeout(time: Integer.parseInt(env.VALIDATION_TIMEOUT), unit: 'MINUTES') {
                                executeInContainer([
                                    "cd ${env.QA_INFRA_WORK_PATH}",
                                    "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
                                    "echo 'Validating cluster nodes...'",
                                    "kubectl get nodes -o wide",
                                    "echo 'Validating system pods...'",
                                    "kubectl get pods -A --field-selector=status.phase!=Running",
                                    "echo 'Validating services...'",
                                    "kubectl get svc -A",
                                    "echo 'Cluster validation completed successfully'"
                                ])
                            }
                        }
                    }
                }
                
                stage('Rancher Validation') {
                    steps {
                        script {
                            logInfo("Validating Rancher deployment")
                            
                            timeout(time: Integer.parseInt(env.VALIDATION_TIMEOUT), unit: 'MINUTES') {
                                executeInContainer([
                                    "cd ${env.QA_INFRA_WORK_PATH}",
                                    "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
                                    "echo 'Validating Rancher pods...'",
                                    "kubectl get pods -n cattle-system",
                                    "echo 'Validating Rancher services...'",
                                    "kubectl get svc -n cattle-system",
                                    "echo 'Checking Rancher ingress...'",
                                    "kubectl get ingress -A",
                                    "echo 'Rancher validation completed successfully'"
                                ])
                            }
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Deployment validation failed")
                }
                always {
                    // Archive validation results regardless of success/failure
                    archiveValidationResults()
                }
            }
        }

    post {
        always {
            script {
                logInfo("Starting post-build cleanup")
                
                // Archive important artifacts
                archiveArtifacts([
                    'kubeconfig.yaml',
                    'terraform.tfstate',
                    'ansible-logs.txt',
                    'deployment-summary.json'
                ])
                
                // Clean up resources
                if (params.CLEANUP_RESOURCES) {
                    cleanupInfrastructure()
                } else {
                    logInfo("Resource cleanup skipped (CLEANUP_RESOURCES=false)")
                    logInfo("Remember to manually clean up AWS resources")
                }
                
                // Always cleanup containers and volumes
                cleanupContainersAndVolumes()
            }
        }
        
        success {
            script {
                logInfo("Pipeline completed successfully")
                sendSlackNotification([
                    color: 'good',
                    message: "‚úÖ Airgap RKE2 deployment succeeded for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
        
        failure {
            script {
                logError("Pipeline failed")
                sendSlackNotification([
                    color: 'danger',
                    message: "‚ùå Airgap RKE2 deployment failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
        
        unstable {
            script {
                logWarning("Pipeline completed with warnings")
                sendSlackNotification([
                    color: 'warning',
                    message: "‚ö†Ô∏è Airgap RKE2 deployment completed with warnings for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
    }
}

/**
 * HELPER FUNCTIONS
 * These functions improve code reusability and maintainability
 */

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def jobNames = jobName.split('/')
        return jobNames[jobNames.size() - 1]
    }
    return jobName
}

def validateParameters() {
    // Validate required parameters
    if (!params.RKE2_VERSION) {
        error("RKE2_VERSION parameter is required")
    }
    if (!params.RANCHER_VERSION) {
        error("RANCHER_VERSION parameter is required")
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error("RANCHER_TEST_REPO_URL parameter is required")
    }
    if (!params.QA_INFRA_REPO_URL) {
        error("QA_INFRA_REPO_URL parameter is required")
    }
    
    // Validate repository URLs format
    if (!params.RANCHER_TEST_REPO_URL.startsWith('https://github.com/') && !params.RANCHER_TEST_REPO_URL.startsWith('git@github.com:')) {
        error("RANCHER_TEST_REPO_URL must be a valid GitHub repository URL")
    }
    if (!params.QA_INFRA_REPO_URL.startsWith('https://github.com/') && !params.QA_INFRA_REPO_URL.startsWith('git@github.com:')) {
        error("QA_INFRA_REPO_URL must be a valid GitHub repository URL")
    }
    
    logInfo("Parameters validated successfully")
}

def setupDynamicEnvironment() {
    // Set environment variables that depend on parameters
    env.RKE2_VERSION = params.RKE2_VERSION
    env.RANCHER_VERSION = params.RANCHER_VERSION

    // Ensure ANSIBLE_TIMEOUT is a valid integer string
    try {
        env.ANSIBLE_TIMEOUT = env.ANSIBLE_TIMEOUT?.isInteger() ? env.ANSIBLE_TIMEOUT : "45"
        Integer.parseInt(env.ANSIBLE_TIMEOUT)
    } catch (Exception e) {
        logWarning("ANSIBLE_TIMEOUT is invalid, defaulting to 45 minutes")
        env.ANSIBLE_TIMEOUT = "45"
    }
    
    logInfo("Dynamic environment configured")
    logInfo("RKE2 Version: ${env.RKE2_VERSION}")
    logInfo("Rancher Version: ${env.RANCHER_VERSION}")
    logInfo("Rancher repository: ${env.RANCHER_TEST_REPO_URL}")
    logInfo("QA Infrastructure repository: ${env.QA_INFRA_REPO}")
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),        
        string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def generateConfigurationFiles() {
    logInfo("Generating configuration files")
    
    // Generate Ansible configuration with secure template replacement
    def ansibleConfig = env.ANSIBLE_CONFIG
    def configReplacements = [
        '${AWS_SECRET_ACCESS_KEY}': env.AWS_SECRET_ACCESS_KEY,
        '${AWS_ACCESS_KEY_ID}': env.AWS_ACCESS_KEY_ID,
        '${RKE2_VERSION}': env.RKE2_VERSION,
        '${RANCHER_VERSION}': env.RANCHER_VERSION
    ]
    
    configReplacements.each { key, value ->
        ansibleConfig = ansibleConfig.replace(key, value ?: '')
    }
    
    // Generate Terraform configuration
    def tofuConfig = env.TERRAFORM_CONFIG
    def tfReplacements = [
        '${AWS_SECRET_ACCESS_KEY}': env.AWS_SECRET_ACCESS_KEY,
        '${AWS_ACCESS_KEY_ID}': env.AWS_ACCESS_KEY_ID,
        '${AWS_REGION}': env.AWS_REGION,
        '${AWS_VPC}': env.AWS_VPC,
        '${AWS_SECURITY_GROUPS}': env.AWS_SECURITY_GROUPS
    ]
    
    tfReplacements.each { key, value ->
        tofuConfig = tofuConfig.replace(key, value ?: '')
    }
    
    // Write configuration files
    dir('./qa-infra-automation') {
        dir('./ansible') {
            writeFile file: env.ANSIBLE_VARS_FILENAME, text: ansibleConfig
        }
        dir('./tofu/aws/modules/airgap') {
            writeFile file: env.TERRAFORM_VARS_FILENAME, text: tofuConfig
        }
    }
    
    logInfo("Configuration files generated successfully")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo("Setting up SSH keys")
        
        dir('./tests/.ssh') {
            // Securely decode and write SSH key
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }
        
        logInfo("SSH keys configured successfully")
    }
}

def buildDockerImage() {
    logInfo("Building Docker image: ${env.IMAGE_NAME}")
    
    dir('./') {
        sh "./tests/validation/configure.sh"
        sh """
            docker build . \
                -f ./tests/validation/Dockerfile.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD) \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}"
        """
    }
    
    logInfo("Docker image built successfully")
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeInContainer(commands) {
    def commandString = commands.join(' && ')
    def dockerCommand = """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            --name ${env.BUILD_CONTAINER_NAME}-\$(date +%s) \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh -c '${commandString}'
    """
    
    sh dockerCommand
}

def getAnsibleVerbosity() {
    switch (params.LOG_LEVEL) {
        case 'DEBUG':
            return '-vvv'
        case 'VERBOSE':
            return '-vvvv'
        default:
            return '-v'
    }
}

def destroyInfrastructure() {
    logInfo("Destroying infrastructure")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            "tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME}",
            "echo 'Infrastructure destroyed successfully'"
        ])
    } catch (Exception e) {
        logError("Infrastructure destruction failed: ${e.message}")
    }
}

def archiveValidationResults() {
    logInfo("Archiving validation results")
    
    try {
        // Copy artifacts from container
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/ansible/rke2/kubeconfig.yaml ./kubeconfig.yaml || true
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/terraform.tfstate ./terraform.tfstate || true
        """
        
        // Generate deployment summary
        def deploymentSummary = [
            buildNumber: env.BUILD_NUMBER,
            rke2Version: env.RKE2_VERSION,
            rancherVersion: env.RANCHER_VERSION,
            timestamp: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'"),
            status: currentBuild.currentResult ?: 'SUCCESS'
        ]
        
        writeJSON file: 'deployment-summary.json', json: deploymentSummary
        
    } catch (Exception e) {
        logError("Failed to archive validation results: ${e.message}")
    }
}

def cleanupInfrastructure() {
    logInfo("Cleaning up infrastructure resources")
    destroyInfrastructure()
}

def cleanupContainersAndVolumes() {
    logInfo("Cleaning up Docker containers and volumes")
    
    sh """
        # Stop and remove any containers with our naming pattern
        docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
        docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true
        
        # Remove the Docker image
        docker rmi -f ${env.IMAGE_NAME} || true
        
        # Remove the shared volume
        docker volume rm -f ${env.VALIDATION_VOLUME} || true
        
        # Clean up any dangling images and volumes
        docker system prune -f || true
    """
}

def archiveArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins',
                color: config.color,
                title: 'Airgap RKE2 Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'RKE2 Version', value: env.RKE2_VERSION, short: true],
                    [title: 'Rancher Version', value: env.RANCHER_VERSION, short: true]
                ]
            ]
            
            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )
            
            logInfo("Slack notification sent successfully")
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * ENHANCED DEVOPS FUNCTIONS
 * Advanced infrastructure and deployment management with monitoring and rollback capabilities
 */

def validateInfrastructurePrerequisites() {
    logInfo("Validating infrastructure prerequisites")
    
    executeInContainer([
        "echo 'Validating AWS credentials and permissions...'",
        "aws sts get-caller-identity",
        "aws ec2 describe-vpcs --max-items 1",
        "echo 'Validating OpenTofu installation...'",
        "tofu version",
        "echo 'Checking required environment variables...'",
        "env | grep -E '^(AWS_|TF_)' | sort",
        "echo 'Prerequisites validation completed'"
    ])
}

def executeInfrastructureSetup() {
    logInfo("Executing infrastructure setup with state management")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "echo 'Initializing OpenTofu with remote state...'",
        "tofu -chdir=tofu/aws/modules/airgap init -input=false -upgrade",
        "echo 'Setting up workspace isolation...'",
        "tofu -chdir=tofu/aws/modules/airgap workspace new ${env.TF_WORKSPACE} || tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}",
        "export TF_WORKSPACE=${env.TF_WORKSPACE}",
        "echo 'Planning infrastructure changes...'",
        "tofu -chdir=tofu/aws/modules/airgap plan -var-file=${env.TERRAFORM_VARS_FILENAME} -out=tfplan",
        "echo 'Applying infrastructure configuration...'",
        "tofu -chdir=tofu/aws/modules/airgap apply tfplan",
        "echo 'Infrastructure provisioned successfully'"
    ])
}

def validateInfrastructureState() {
    logInfo("Validating infrastructure state and connectivity")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "echo 'Validating infrastructure outputs...'",
        "tofu -chdir=tofu/aws/modules/airgap output",
        "echo 'Testing connectivity to provisioned resources...'",
        "tofu -chdir=tofu/aws/modules/airgap output -json > infrastructure_outputs.json",
        "echo 'Infrastructure state validation completed'"
    ])
}

def cacheInfrastructureOutputs() {
    logInfo("Caching infrastructure outputs for pipeline stages")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "mkdir -p /tmp/pipeline-cache",
        "tofu -chdir=tofu/aws/modules/airgap output -json > /tmp/pipeline-cache/infrastructure.json",
        "echo 'Infrastructure outputs cached successfully'"
    ])
}

def handleInfrastructureFailure(Exception e) {
    logError("Handling infrastructure failure: ${e.message}")
    
    // Collect diagnostic information
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "echo 'Collecting infrastructure diagnostic information...'",
            "tofu -chdir=tofu/aws/modules/airgap show -json > /tmp/terraform-state-dump.json || true",
            "tofu -chdir=tofu/aws/modules/airgap plan -var-file=${env.TERRAFORM_VARS_FILENAME} -detailed-exitcode || true",
            "aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,State.Name,PublicIpAddress]' --output table || true"
        ])
    } catch (Exception diagException) {
        logError("Failed to collect diagnostic information: ${diagException.message}")
    }
}

def rollbackInfrastructure() {
    logInfo("Initiating infrastructure rollback")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "echo 'Starting infrastructure rollback...'",
            "tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            "tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME}",
            "echo 'Infrastructure rollback completed'"
        ])
    } catch (Exception e) {
        logError("Infrastructure rollback failed: ${e.message}")
        // Send critical alert
        sendSlackNotification([
            color: 'danger',
            message: "üö® CRITICAL: Infrastructure rollback failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}. Manual intervention required!"
        ])
    }
}

def publishInfrastructureMetrics() {
    logInfo("Publishing infrastructure metrics")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "echo 'Collecting infrastructure metrics...'",
            "tofu -chdir=tofu/aws/modules/airgap output -json | jq '.instance_count.value' > /tmp/instance_count.txt || echo '0' > /tmp/instance_count.txt",
            "aws ec2 describe-instances --query 'Reservations[].Instances[?State.Name==`running`]' --output json | jq 'flatten | length' > /tmp/running_instances.txt || echo '0' > /tmp/running_instances.txt",
            "echo 'Infrastructure metrics collected'"
        ])
    } catch (Exception e) {
        logWarning("Failed to publish infrastructure metrics: ${e.message}")
    }
}

def validateClusterPrerequisites() {
    logInfo("Validating cluster deployment prerequisites")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "echo 'Validating Ansible configuration...'",
        "ansible --version",
        "ansible-inventory -i ansible/rke2/terraform-inventory.yml --list",
        "echo 'Testing SSH connectivity to nodes...'",
        "ansible -i ansible/rke2/terraform-inventory.yml all -m ping -e @ansible/${env.ANSIBLE_VARS_FILENAME}",
        "echo 'Cluster prerequisites validated'"
    ])
}

def deployRKE2WithMonitoring() {
    logInfo("Deploying RKE2 cluster with progress monitoring")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "export ANSIBLE_CONFIG=ansible/rke2/ansible.cfg",
        "export ANSIBLE_PRIVATE_KEY_FILE=/root/.ssh/jenkins-elliptic-validation.pem",
        "echo 'Starting RKE2 airgap deployment with monitoring...'",
        "ansible-playbook -i ansible/rke2/terraform-inventory.yml " +
        "ansible/rke2/airgap/playbooks/deploy/rke2-tarball-playbook.yml " +
        "${getAnsibleVerbosity()} -e @ansible/${env.ANSIBLE_VARS_FILENAME} " +
        "--extra-vars 'monitoring_enabled=true'",
        "echo 'RKE2 airgap cluster deployed successfully'"
    ])
}

def validateClusterHealth() {
    logInfo("Validating cluster health and readiness")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
        "echo 'Validating cluster nodes status...'",
        "kubectl get nodes -o wide",
        "kubectl wait --for=condition=Ready nodes --all --timeout=300s",
        "echo 'Validating system pods...'",
        "kubectl get pods -n kube-system",
        "kubectl wait --for=condition=Ready pods --all -n kube-system --timeout=300s",
        "echo 'Cluster health validation completed'"
    ])
}

def handleClusterDeploymentFailure(Exception e) {
    logError("Handling cluster deployment failure: ${e.message}")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "echo 'Collecting cluster diagnostic information...'",
            "kubectl get events --all-namespaces --sort-by='.lastTimestamp' || true",
            "kubectl describe nodes || true",
            "journalctl -u rke2-server --no-pager -n 100 || true",
            "systemctl status rke2-server || true"
        ])
    } catch (Exception diagException) {
        logError("Failed to collect cluster diagnostics: ${diagException.message}")
    }
}

def archiveClusterArtifacts() {
    logInfo("Archiving cluster artifacts")
    
    try {
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/ansible/rke2/kubeconfig.yaml ./kubeconfig.yaml || true
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):/tmp/cluster-info.yaml ./cluster-info.yaml || true
        """
    } catch (Exception e) {
        logWarning("Failed to archive cluster artifacts: ${e.message}")
    }
}

def collectClusterDiagnostics() {
    logInfo("Collecting comprehensive cluster diagnostics")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "mkdir -p /tmp/diagnostics",
            "kubectl cluster-info dump --output-directory=/tmp/diagnostics/cluster-dump || true",
            "kubectl get events --all-namespaces --sort-by='.lastTimestamp' -o yaml > /tmp/diagnostics/events.yaml || true",
            "kubectl get nodes -o yaml > /tmp/diagnostics/nodes.yaml || true",
            "kubectl get pods --all-namespaces -o yaml > /tmp/diagnostics/pods.yaml || true"
        ])
        
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):/tmp/diagnostics ./cluster-diagnostics/ || true
        """
    } catch (Exception e) {
        logError("Failed to collect cluster diagnostics: ${e.message}")
    }
}

def validateNetworkSecurity() {
    logInfo("Validating network security policies")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "echo 'Checking network policies...'",
        "kubectl get networkpolicies --all-namespaces || true",
        "echo 'Validating security groups...'",
        "aws ec2 describe-security-groups --query 'SecurityGroups[*].[GroupId,GroupName,Description]' --output table || true",
        "echo 'Network security validation completed'"
    ])
}

def validateResourceCompliance() {
    logInfo("Validating resource compliance")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "echo 'Checking resource limits...'",
        "kubectl describe limitranges --all-namespaces || true",
        "kubectl describe resourcequotas --all-namespaces || true",
        "echo 'Validating pod security standards...'",
        "kubectl get pods --all-namespaces -o jsonpath='{.items[*].spec.securityContext}' || true",
        "echo 'Resource compliance validation completed'"
    ])
}

def validateAccessControls() {
    logInfo("Validating access controls and RBAC")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "echo 'Checking RBAC configuration...'",
        "kubectl get clusterroles,clusterrolebindings,roles,rolebindings --all-namespaces || true",
        "echo 'Validating service accounts...'",
        "kubectl get serviceaccounts --all-namespaces || true",
        "echo 'Access control validation completed'"
    ])
}

def waitForClusterReadiness() {
    logInfo("Waiting for cluster readiness before Rancher deployment")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
        "echo 'Waiting for cluster to be fully ready...'",
        "kubectl wait --for=condition=Ready nodes --all --timeout=600s",
        "kubectl wait --for=condition=Ready pods --all -n kube-system --timeout=300s",
        "echo 'Cluster is ready for Rancher deployment'"
    ])
}

def deployRancherWithMonitoring() {
    logInfo("Deploying Rancher with integrated monitoring")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
        "echo 'Starting Rancher airgap deployment with monitoring...'",
        "ansible-playbook ansible/rancher/playbooks/deploy/rancher-airgap-playbook.yml " +
        "${getAnsibleVerbosity()} -e @ansible/${env.ANSIBLE_VARS_FILENAME} " +
        "--extra-vars 'enable_monitoring=true deployment_monitoring=true'",
        "echo 'Rancher deployed successfully on airgap cluster'"
    ])
}

def validateRancherIntegration() {
    logInfo("Validating Rancher integration and services")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
        "echo 'Validating Rancher pods...'",
        "kubectl get pods -n cattle-system",
        "kubectl wait --for=condition=Ready pods --all -n cattle-system --timeout=600s",
        "echo 'Validating Rancher services...'",
        "kubectl get svc -n cattle-system",
        "echo 'Checking Rancher ingress...'",
        "kubectl get ingress -A",
        "echo 'Rancher integration validation completed'"
    ])
}

def runRancherSmokeTests() {
    logInfo("Running Rancher smoke tests")
    
    executeInContainer([
        "cd ${env.QA_INFRA_WORK_PATH}",
        "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
        "echo 'Running basic Rancher API health checks...'",
        "kubectl get --raw='/readyz' || true",
        "kubectl get --raw='/healthz' || true",
        "echo 'Testing Rancher UI accessibility...'",
        "curl -k -s -o /dev/null -w '%{http_code}' https://rancher.local/dashboard/ || echo 'UI check completed'",
        "echo 'Rancher smoke tests completed'"
    ])
}

def handleRancherDeploymentFailure(Exception e) {
    logError("Handling Rancher deployment failure: ${e.message}")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
            "echo 'Collecting Rancher diagnostic information...'",
            "kubectl logs -n cattle-system -l app=rancher --tail=100 || true",
            "kubectl describe pods -n cattle-system || true",
            "kubectl get events -n cattle-system --sort-by='.lastTimestamp' || true"
        ])
    } catch (Exception diagException) {
        logError("Failed to collect Rancher diagnostics: ${diagException.message}")
    }
}

def publishDeploymentMetrics() {
    logInfo("Publishing deployment metrics and summary")
    
    try {
        def deploymentSummary = [
            buildNumber: env.BUILD_NUMBER,
            rke2Version: env.RKE2_VERSION,
            rancherVersion: env.RANCHER_VERSION,
            deploymentTime: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'"),
            status: 'SUCCESS',
            infraNodes: getInfrastructureNodeCount(),
            rancherPods: getRancherPodCount()
        ]
        
        writeJSON file: 'deployment-metrics.json', json: deploymentSummary
        
        logInfo("Deployment metrics published successfully")
    } catch (Exception e) {
        logWarning("Failed to publish deployment metrics: ${e.message}")
    }
}

def collectRancherDiagnostics() {
    logInfo("Collecting comprehensive Rancher diagnostics")
    
    try {
        executeInContainer([
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export KUBECONFIG=ansible/rke2/kubeconfig.yaml",
            "mkdir -p /tmp/rancher-diagnostics",
            "kubectl logs -n cattle-system --all-containers=true > /tmp/rancher-diagnostics/cattle-system-logs.txt || true",
            "kubectl get all -n cattle-system -o yaml > /tmp/rancher-diagnostics/cattle-system-resources.yaml || true",
            "kubectl describe pods -n cattle-system > /tmp/rancher-diagnostics/pod-descriptions.txt || true"
        ])
        
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):/tmp/rancher-diagnostics ./rancher-diagnostics/ || true
        """
    } catch (Exception e) {
        logError("Failed to collect Rancher diagnostics: ${e.message}")
    }
}

def getInfrastructureNodeCount() {
    try {
        def output = sh(
            script: "docker exec \$(docker ps -aqf \"name=${env.BUILD_CONTAINER_NAME}\") sh -c \"cd ${env.QA_INFRA_WORK_PATH} && kubectl get nodes --no-headers | wc -l\"",
            returnStdout: true
        ).trim()
        return output.toInteger()
    } catch (Exception e) {
        logWarning("Failed to get node count: ${e.message}")
        return 0
    }
}

def getRancherPodCount() {
    try {
        def output = sh(
            script: "docker exec \$(docker ps -aqf \"name=${env.BUILD_CONTAINER_NAME}\") sh -c \"cd ${env.QA_INFRA_WORK_PATH} && kubectl get pods -n cattle-system --no-headers | wc -l\"",
            returnStdout: true
        ).trim()
        return output.toInteger()
    } catch (Exception e) {
        logWarning("Failed to get Rancher pod count: ${e.message}")
        return 0
    }
}

/**
 * LOGGING FUNCTIONS
 * Provide structured logging with different levels
 */

def logInfo(message) {
    echo "‚ÑπÔ∏è [INFO] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logError(message) {
    echo "‚ùå [ERROR] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logWarning(message) {
    echo "‚ö†Ô∏è [WARNING] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logDebug(message) {
    if (params.LOG_LEVEL == 'DEBUG' || params.LOG_LEVEL == 'VERBOSE') {
        echo "üîç [DEBUG] ${new Date().format('HH:mm:ss')} - ${message}"
    }
}